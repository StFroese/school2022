{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d42031-47a4-4562-91ae-0bd53d74a945",
   "metadata": {},
   "source": [
    "# Escape Summer School - Classification, Performance Evaluation & Hyper-parameter Optimization\n",
    "\n",
    "### Classification\n",
    "\n",
    "- The task for which the `digits` dataset was originally devised is, of course, identifying which handwritten digit is in each image.\n",
    "- This is a useful task in the real world, where machines read postcodes on letters to sort them, and digits on cheques to validate them automatically.\n",
    "- We have labels in the training dataset, therefore this is a **supervised classification** task. Supervised classification is the most common of modern ML tasks.\n",
    "\n",
    "### Support Vector Classifiers\n",
    "\n",
    "- Today, large-scale, high-dimensional classification tasks on complex data are almost always solved with deep neural networks.\n",
    "- However, simpler algorithms are still used for smaller and lower-dimensional datasets. One of these is called the Support Vector Classifier.\n",
    "\n",
    "Before we proceed, it's time to introduce the split between training set and test set.\n",
    "- Having a separate test set, composed of data kept out of the training, is important in order to check whether our model is able to *generalise properly* on data it has not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3feaed1-6813-4060-bc00-238502cd29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3223fd-8eee-4693-ae77-920dd44022b3",
   "metadata": {},
   "source": [
    "### Load the dataset and plot some images along with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec1f6a-b7c8-41d3-a26e-1a93aa735826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "np.random.seed(0)\n",
    "digits = load_digits()\n",
    "\n",
    "images = digits['images'] # The real digit images of size (N, 8, 8)\n",
    "X = digits['data'] # The vectorised data of size (N, 64)\n",
    "y = digits['target']\n",
    "N = len(images)\n",
    "print('Number of digits :', N)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, r in enumerate(randint(0, N, 5)):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(images[r], cmap=\"gray\")\n",
    "    plt.title('Label : ' + str(y[r]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f8bc5-6b06-4f12-8d3b-f742c49f89d5",
   "metadata": {},
   "source": [
    "## Classification without cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86cf29",
   "metadata": {},
   "source": [
    "### Split in train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = #TODO\n",
    "\n",
    "print('Training set shape :', X_train.shape)\n",
    "print('Test set shape     :', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8268f1-7d5e-4a58-b098-3ba7dc23f49e",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a1f9f-0777-42b0-b02d-1ea7c161b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernel = #TODO\n",
    "gamma = #TODO\n",
    "svc = #TODO\n",
    "\n",
    "# training\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# looking at prediction on test set\n",
    "y_pred = #TODO\n",
    "\n",
    "# accuracy of the model\n",
    "accuracy = sum(y_pred == y_test) / len(y_pred)\n",
    "print(\"%0.5f accuracy\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff67f48-bb8c-46c6-9b14-ee20bba3b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay. #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38307537-46c2-4a8a-aa9a-851ae63abdbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification with Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eef6f2-67aa-41dd-aea1-5fc0c2d76746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = #TODO\n",
    "\n",
    "print(\"%0.5f accuracy with a standard deviation of %0.5f\" % (scores['test_score'].mean(), scores['test_score'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9e062-0e4b-4241-8ea7-9dacbca7bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = []\n",
    "for estimator in #TODO:\n",
    "    y_pred = #TODO\n",
    "    accuracy = sum(y_pred == y_test) / len(y_pred)\n",
    "    scores_test.append(accuracy)\n",
    "    \n",
    "print(\"%0.5f accuracy with a standard deviation of %0.5f\" % (np.mean(scores_test), np.std(scores_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb5d1e-17a0-4b24-af81-f811e2f9e319",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d854376-4e8c-4223-9e7c-73e11ea534bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "C = #TODO\n",
    "gamma = #TODO\n",
    "\n",
    "param_grid = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": gamma, \"C\": C},\n",
    "    {\"kernel\": [\"linear\"], \"C\": C},\n",
    "]\n",
    "\n",
    "grid_search = #TODO\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set :\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a120a-148f-4a07-b8ca-d31840c97474",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_search.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_search.cv_results_[\"std_test_score\"]\n",
    "\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca16a0f-52e9-4220-83a0-a70f5404ec12",
   "metadata": {},
   "source": [
    "## ROC curves\n",
    "\n",
    "The objective is to compute the ROC curves of a classifier trained to distinguish between even and odd numbers for different combinaisons of data dimensionnality reduction (using PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f8dcc-4dfe-4c98-ad76-7babcd7c42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "\n",
    "y_train = y_train % 2 == 0 # Even or odd\n",
    "y_test = y_test % 2 == 0 # Even or odd\n",
    "\n",
    "X_train_pca = #TODO\n",
    "X_test_pca = #TODO\n",
    "\n",
    "plt.scatter(\n",
    "    X_train_pca[y_train==True, 0], \n",
    "    X_train_pca[y_train==True, 1], \n",
    "    c='b', \n",
    "    s=100,\n",
    "    label='Even',\n",
    "    alpha=0.3, \n",
    "    edgecolors='none'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    X_train_pca[y_train==False, 0], \n",
    "    X_train_pca[y_train==False, 1], \n",
    "    c='r', \n",
    "    s=100,\n",
    "    label='Odd',\n",
    "    alpha=0.3, \n",
    "    edgecolors='none'\n",
    ")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5cc3f-8380-4296-bd5f-9de8019284ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "svc = #TODO # Best classifier according to grid search\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for n in range(1, 10):\n",
    "    pca = #TODO\n",
    "    pca.fit(X_train)\n",
    "    \n",
    "    X_train_pca = #TODO\n",
    "    X_test_pca = #TODO\n",
    "    \n",
    "    svc.fit(X_train_pca, y_train)\n",
    "    \n",
    "    y_pred = #TODO\n",
    "    \n",
    "    # accuracy of the model\n",
    "    accuracy = sum(y_pred == y_test) / len(y_pred)\n",
    "    print(\"%0.5f accuracy for %d PC(s)\" % (accuracy, n))\n",
    "    \n",
    "    viz = RocCurveDisplay.#TODO\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a97d4-f3e3-462a-ab0d-6af7b858a9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "execution": {
      "allow_errors": true,
      "timeout": 300
    },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
